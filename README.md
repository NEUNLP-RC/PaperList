# PaperList

by neulab

Enriching Pre-trained Language Model with Entity Information for Relation Classification.

Attention Is All You Need.(https://jalammar.github.io/illustrated-transformer/  作者对论文的图解，容易理解)

BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.
